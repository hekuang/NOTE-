{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"0\"> </a>\n",
    "## 目录\n",
    "\n",
    "- [第1章. 统计学及方法概论](#1)\n",
    "- [第2章. 感知机](#2)\n",
    "- [第3章. k 近邻法](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1\"></a>\n",
    "# [第1章. 统计学及方法概论](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.统计学习\n",
    "\n",
    "假设空间：模型，某个函数合集 （输入空间到输出空间映射的合集） \n",
    "假设空间 ==评价准则==>> 最优模型 ( 最优模型的选取，又算法实现）\n",
    "\n",
    "**算法**根据**评价准则（策略）**利用训练数据在**假设空间**中选择出最优模型，利用最优模型对新数据进行预测或分析\n",
    "\n",
    "\n",
    "## 1.2.监督学习\n",
    "\n",
    "输入：具体输入也叫实例（instance），也是欧式空间的一个特征向量（feature vector) ，所以特征向量合集叫做特征空间\n",
    "\n",
    "- 方法： \n",
    "     - 分类：输入变量为有限离散变量\n",
    "     - 标记：输入输出变量均为变量序列\n",
    "     - 回归：输入与输出变量均为连续变量\n",
    "     \n",
    "- P(X,Y)分布函数，对于系统来说是未知的\n",
    "\n",
    "\n",
    "## 1.3. 统计学习三要素\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计学习方法 = 模型 +　策略 + 算法\n",
    "\n",
    "### 模型\n",
    "> 要学习的条件概率P(Y|X)或决策函数Y=f（X)  \n",
    "模型的假设空间：所有要学习的条件概率P(Y|X)或决策函数Y=f（X)\n",
    "\n",
    "### 策略 （准测）\n",
    "统计学习目的：从假设空间选取最优模型 ，选择期望风险最小的模型   \n",
    "- 损失函数L：度量模型**一次**预测的好坏，预测的错误程度，越低越好\n",
    "- 风险函数(期望损失)R: 度量**平均**意义下模拟预测的好坏\n",
    "> 样本的分布无限接近无联合分布P(X,Y)，经验风险（模型关于训练样本）就无限趋于期望风险（期望损失）\n",
    "- 经验风险最小化（empirical risk minimization, ERM ): 经验风险最小= 最优模型\n",
    "> 样本不足，容易过拟合\n",
    "- 结构风险最小化（ structural risk minimization, SRM): 等价于正则化。  \n",
    "经验风险上加入正则化项目或罚项\n",
    "\n",
    "### 算法\n",
    "> 模型的具体计算方法，找到全局最优解。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. 模型评估与模型选择\n",
    "\n",
    "### 训练误差与测试误差\n",
    "\n",
    "- 训练误差(training error ): 判定给定问题是否容易学习，本质**不重要**\n",
    "- 测试误差(test error): 反映学习方法对未知的测试数据集的预测能力（**泛化能力**），是学习中的重要概念\n",
    "- \n",
    "\n",
    "### 过拟合与模型选择\n",
    "- 模型参数过多，对已知数据预测很好，对未知数据预测很差\n",
    "\n",
    "\n",
    "## 1.5.正则化与交叉验证\n",
    "\n",
    "### 正则化\n",
    "- 结构风险最小化，经验风险上加一个正则化项（regularizer）或罚项（penalty term）\n",
    "- 正则化项一般是模型复杂度的单调递增函数，可以是模型参数向量的范数 \n",
    "\n",
    "### 交叉验证\n",
    "\n",
    "数据集分为：训练集，验证集，测试集。\n",
    "- 简单交叉验证，随机将已知数据分为训练和测试集（如7：3）\n",
    "- S折交叉验证（又名K折交叉法）： 数据集分为S个不相交相等子集，S-1：1的比例训练测试N次\n",
    "- 留一交叉验证：在S折交叉验证将S= N，在数据缺乏下使用。N是给定数据集的容量\n",
    "\n",
    "\n",
    "<img src = \"./img/K折交叉.png\" width = \"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6.泛化能力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"2\"></a>\n",
    "# [第二章. 感知机](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  二分类的线性分类模型\n",
    "- 输入：实例的特征向量  输出：实例的类别（+1，-1）\n",
    "- 简单易于实现，分为原始形式和对偶形式。是神经网络，支持向量机的基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.感知机模型\n",
    "\n",
    "$$f(x)=  sign(w\\cdot x+b)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.感知机学习策略\n",
    "\n",
    "#### 数据集线性可分\n",
    "存在超平面$S$ 可完全正确的划分数据集到两侧\n",
    "\n",
    "### 感知机学习策略\n",
    "\n",
    "找出上述超平面$S$，确认 w和b， 定义损失函数，并将其最小化\n",
    "\n",
    "损失函数：\n",
    "$$L(w,b) = -\\sum_{x_i\\in{M}}y_i(w\\cdot x_i+b) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
